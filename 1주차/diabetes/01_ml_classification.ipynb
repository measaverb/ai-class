{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Diabetes Classification using Classical Machine Learning Algorithms"]},{"cell_type":"markdown","metadata":{},"source":["## Comparison on Support Vector Machine, Logistic Regression, Random Forest, Decision Tree and KNN"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df = pd.read_csv('data/diabetes.csv')\n","\n","X = df.drop('Outcome', axis=1)\n","y = df['Outcome']"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["models = {\n","    'SVM': Pipeline([\n","        ('scaler', StandardScaler()),   # Add scaler for leveraging dataset statistics\n","        ('svm', SVC(random_state=42))\n","    ]),\n","    'Logistic Regression': Pipeline([\n","        ('scaler', StandardScaler()),\n","        ('lr', LogisticRegression(random_state=42))\n","    ]),\n","    'Random Forest': RandomForestClassifier(random_state=42),\n","    'Decision Tree': DecisionTreeClassifier(random_state=42),\n","    'KNN': Pipeline([\n","        ('scaler', StandardScaler()),\n","        ('knn', KNeighborsClassifier())\n","    ])\n","}\n","\n","param_grids = {     # Set pre-defined hyperparameter ranges for finding optimal hyperparemter\n","    'SVM': {'svm__C': [0.1, 1, 10], 'svm__kernel': ['rbf', 'linear']},\n","    'Logistic Regression': {'lr__C': [0.1, 1, 10]},\n","    'Random Forest': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n","    'Decision Tree': {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n","    'KNN': {'knn__n_neighbors': [3, 5, 7, 9]}\n","}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training SVM...\n","SVM - Validation Accuracy: 0.7236\n","SVM - Test Accuracy: 0.7143\n","SVM - CV Accuracy: 0.7577 (+/- 0.0390)\n","SVM - Best Parameters: {'svm__C': 1, 'svm__kernel': 'rbf'}\n","Classification Report (Test Set):\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.82      0.79        99\n","           1       0.62      0.53      0.57        55\n","\n","    accuracy                           0.71       154\n","   macro avg       0.69      0.67      0.68       154\n","weighted avg       0.71      0.71      0.71       154\n","\n","\n","==================================================\n","\n","Training Logistic Regression...\n","Logistic Regression - Validation Accuracy: 0.7886\n","Logistic Regression - Test Accuracy: 0.7273\n","Logistic Regression - CV Accuracy: 0.7576 (+/- 0.0416)\n","Logistic Regression - Best Parameters: {'lr__C': 1}\n","Classification Report (Test Set):\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.77      0.78        99\n","           1       0.61      0.65      0.63        55\n","\n","    accuracy                           0.73       154\n","   macro avg       0.71      0.71      0.71       154\n","weighted avg       0.73      0.73      0.73       154\n","\n","\n","==================================================\n","\n","Training Random Forest...\n","Random Forest - Validation Accuracy: 0.7724\n","Random Forest - Test Accuracy: 0.7273\n","Random Forest - CV Accuracy: 0.7597 (+/- 0.0316)\n","Random Forest - Best Parameters: {'max_depth': None, 'n_estimators': 100}\n","Classification Report (Test Set):\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.78      0.79        99\n","           1       0.61      0.64      0.62        55\n","\n","    accuracy                           0.73       154\n","   macro avg       0.70      0.71      0.71       154\n","weighted avg       0.73      0.73      0.73       154\n","\n","\n","==================================================\n","\n","Training Decision Tree...\n","Decision Tree - Validation Accuracy: 0.6341\n","Decision Tree - Test Accuracy: 0.7208\n","Decision Tree - CV Accuracy: 0.7353 (+/- 0.0565)\n","Decision Tree - Best Parameters: {'max_depth': None, 'min_samples_split': 10}\n","Classification Report (Test Set):\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.77      0.78        99\n","           1       0.60      0.64      0.62        55\n","\n","    accuracy                           0.72       154\n","   macro avg       0.70      0.70      0.70       154\n","weighted avg       0.72      0.72      0.72       154\n","\n","\n","==================================================\n","\n","Training KNN...\n","KNN - Validation Accuracy: 0.7073\n","KNN - Test Accuracy: 0.7338\n","KNN - CV Accuracy: 0.7434 (+/- 0.0691)\n","KNN - Best Parameters: {'knn__n_neighbors': 5}\n","Classification Report (Test Set):\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.83      0.80        99\n","           1       0.65      0.56      0.60        55\n","\n","    accuracy                           0.73       154\n","   macro avg       0.71      0.70      0.70       154\n","weighted avg       0.73      0.73      0.73       154\n","\n","\n","==================================================\n","\n"]}],"source":["results = {}\n","\n","for name, model in models.items():\n","    print(f\"Training {name}...\")\n","    \n","    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n","    grid_search.fit(X_train, y_train)\n","    \n","    best_model = grid_search.best_estimator_\n","    \n","    y_val_pred = best_model.predict(X_val)\n","    \n","    val_accuracy = accuracy_score(y_val, y_val_pred)\n","    \n","    y_test_pred = best_model.predict(X_test)\n","    \n","    test_accuracy = accuracy_score(y_test, y_test_pred)\n","    \n","    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n","    \n","    results[name] = {\n","        'Best Parameters': grid_search.best_params_,\n","        'Validation Accuracy': val_accuracy,\n","        'Test Accuracy': test_accuracy,\n","        'Cross-Validation Mean': cv_scores.mean(),\n","        'Cross-Validation Std': cv_scores.std()\n","    }\n","    \n","    print(f\"{name} - Validation Accuracy: {val_accuracy:.4f}\")\n","    print(f\"{name} - Test Accuracy: {test_accuracy:.4f}\")\n","    print(f\"{name} - CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n","    print(f\"{name} - Best Parameters: {grid_search.best_params_}\")\n","    print(\"Classification Report (Test Set):\")\n","    print(classification_report(y_test, y_test_pred))\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary of Results:\n","SVM:\n","\tValidation Accuracy: 0.7236\n","\tTest Accuracy: 0.7143\n","\tCV Accuracy: 0.7577 (+/- 0.0390)\n","\tBest Parameters: {'svm__C': 1, 'svm__kernel': 'rbf'}\n","Logistic Regression:\n","\tValidation Accuracy: 0.7886\n","\tTest Accuracy: 0.7273\n","\tCV Accuracy: 0.7576 (+/- 0.0416)\n","\tBest Parameters: {'lr__C': 1}\n","Random Forest:\n","\tValidation Accuracy: 0.7724\n","\tTest Accuracy: 0.7273\n","\tCV Accuracy: 0.7597 (+/- 0.0316)\n","\tBest Parameters: {'max_depth': None, 'n_estimators': 100}\n","Decision Tree:\n","\tValidation Accuracy: 0.6341\n","\tTest Accuracy: 0.7208\n","\tCV Accuracy: 0.7353 (+/- 0.0565)\n","\tBest Parameters: {'max_depth': None, 'min_samples_split': 10}\n","KNN:\n","\tValidation Accuracy: 0.7073\n","\tTest Accuracy: 0.7338\n","\tCV Accuracy: 0.7434 (+/- 0.0691)\n","\tBest Parameters: {'knn__n_neighbors': 5}\n"]}],"source":["print(\"Summary of Results:\")\n","for name, result in results.items():\n","    print(f\"{name}:\")\n","    print(f\"\\tValidation Accuracy: {result['Validation Accuracy']:.4f}\")\n","    print(f\"\\tTest Accuracy: {result['Test Accuracy']:.4f}\")\n","    print(f\"\\tCV Accuracy: {result['Cross-Validation Mean']:.4f} (+/- {result['Cross-Validation Std'] * 2:.4f})\")\n","    print(f\"\\tBest Parameters: {result['Best Parameters']}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best performing model: Logistic Regression\n","Validation Accuracy: 0.7886\n","Test Accuracy: 0.7273\n"]}],"source":["best_model = max(results, key=lambda x: results[x]['Validation Accuracy'])\n","print(f\"Best performing model: {best_model}\")\n","print(f\"Validation Accuracy: {results[best_model]['Validation Accuracy']:.4f}\")\n","print(f\"Test Accuracy: {results[best_model]['Test Accuracy']:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"ai-class","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":2}
