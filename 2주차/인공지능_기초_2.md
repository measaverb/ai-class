# 2주차 수업

## 저번 주 리뷰

- 인공지능과 딥러닝의 차이점

인공지능: 인간의 지능을 인공적으로 모사하려는 연구 분야. Genetic Algorithm, Expert System 등이 포함됨.
딥러닝: 인공지능을 만들기 위하여 다층의 퍼셉트론을 쌓는 방법론. 다층 퍼셉트론으로 입력과 출력 간 룰 (y = f(x), x-y 간 상관관계) 을 찾아내어 새로운 입력 데이터가 들어왔을 때, 출력을 예상하는 프로세스.

- 지도학습, 준지도학습, 비지도학습, 자기지도학습, 강화학습

- 사례기반학습 vs 모델기반학습

- 전이 학습 (fine-tuning) 실습 예정

- 데이터 이슈 | 샘플 데이터 편향성, 저품질 데이터 (이상치, 노이즈 많음)

- 데이터 이슈를 해결하기 위한 feature engineering, feature selection

- Underfitting: 훈련이 덜 되어 상관관계를 모델링하지 못함. 모델을 더 복잡하게 설계하거나, 더 훈련으로 해결

- Overfitting: 데이터를 암기하여 노이즈, 이상치까지 학습하게 됨. Generalisation에서 문제 있음. Regularisation, Dropout, Early Stopping 등으로 해결

## 이번 주 메인 수업

- 교차검증, K-fold 교차검증의 의미와 차이

네트워크가 상관관계를 잘 모델링할 수 있는지를 데이터 품질에 무관하게 검증할 수 있도록 하는 기법

Cross validation: train set과 valid set의 배합을 바꾸어가며 독립적인 훈련 세션을 진행하는 기법

K-fold cross validation: 전체 데이터셋을 k 개로 나누어 1개의 분할을 valid set, 나머지를 train set으로 하여 k 번 훈련 세션 진행

- 손실 함수의 종류

Binary Cross Entropy Loss - 이진 분류 문제를 위하여

Categorical Cross Entropy Loss - multi-class 분류 문제를 위하여

Mean Squared Error Loss - regression 문제를 위하여; (|y - y_hat|)^2

Mean Absolute Error Loss - regression 문제를 위하여; (|y - y_hat|)

- One Hot Encoding

0, 1, 2, 3으로 출력할 시 종속적인 관계가 되기 때문에 독립적인 관계로 만들기 위하여 (1,0,0,...,0), (0,1,0,...,0), ..., (0,0,0,...1) 형식으로 만듦.

- 하이퍼파라미터 튜닝이란 무엇인가?

하이퍼파라미터: 훈련 세션을 진행할 때 필요한 매개변수 (예: 모델 - 레이어 개수, optimiser: learning rate)

하이퍼파라미터 튜닝: 좋은 성능을 내기 위하여 하이퍼파라미터의 여러 조합을 실험하는 것

하이퍼파라미터 튜닝은 수동으로 하거나 자동으로 할 수 있는데, 자동으로 할 수 있는 방법은 Grid Search, CV, Bayesian Optimsation 등이 있다.

- Metrics

Confusion Matrix: True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN)

Accuracy: (TP + TN) / (TP + TN + FP + FN), Imbalacned dataset에서 fail 할 가능성 있음. F1 score 에서 후술

Precision:

Recall (재현율): Imbalanced dataset에서 사용

F1 Score: Imbalanced dataset으로 훈련하거나 테스트를 할 때, accuracy가 높지만 모델이 일반화를 잘 하지 못할 가능성 (모델이 훈련 데이터 내 최빈값만 출력) 있음. 이를 보완하기 위하여 F1 score 사용

ROC Curve: The curve between recall and fall-out, ROC AUC: The area under the curve

- Logistic regression

y = Wx + b 형태의 그래프를 이용하여 classification 진행

- Decision Tree (Impurity and Gini Index)

Impurity: 데이터를 파티션으로 나누는 기준에 따른 비율, 분류는 특정 군 안에서 impurity를 1로 올리는 것

Gini Index: 데이터를 파티션으로 나누는 기준이 됨

- Random Forest

Decision Tree의 확장, Bootstrapping을 추가한 ensemble 형태의 decision tree

Bootstrapping: 훈련 데이터를 샘플링 할 때 중복된 데이터를 샘플링 할 수 있도록 허용

- Bagging

- Principle Component Analysis
